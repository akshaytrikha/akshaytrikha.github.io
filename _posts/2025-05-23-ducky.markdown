---
layout: post
title: "AI Rubber Ducky Pair Programmer"
date: 2025-05-23 16:06:17 +0000
categories: deep-learning
thumbnail: /assets/thumbnails/ducky.jpeg
tldr: "quack"
---

Please try out the extension on the VSCode extension marketplace and let me know what you think! Enter your email to get access:


<!-- gated signup + link reveal -->
<div id="signup-container">
  <form id="signup-form">
    <input
      type="email"
      id="email-input"
      name="email"
      placeholder="you@domain.com"
      required
    />
    <button type="submit">Sign up ‚Üí</button>
  </form>
</div>

<div id="link-container" style="display:none; margin-top:1em;">
  <a
    href="https://marketplace.visualstudio.com/items?itemName=duckydev.duckydev"
    target="_blank"
    rel="noopener"
  >
    üê§ Get the Ducky VSCode extension
  </a>
</div>

<script src="https://cdn.jsdelivr.net/npm/@supabase/supabase-js"></script>
<script>
  // initialize Supabase client
  const supabaseClient = supabase.createClient(
    'https://jpwoombwzqxfxebrpzkl.supabase.co',
    'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6Impwd29vbWJ3enF4ZnhlYnJwemtsIiwicm9sZSI6ImFub24iLCJpYXQiOjE3NDgyMTY4NDgsImV4cCI6MjA2Mzc5Mjg0OH0.UzRsuRw63TN6rFNtLtBpXZy8JKvrzH1tliS7D_SgI50'
  );

  const form            = document.getElementById('signup-form');
  const emailInput      = document.getElementById('email-input');
  const signupContainer = document.getElementById('signup-container');
  const linkContainer   = document.getElementById('link-container');

  // if user already signed up, show the link immediately
  if (localStorage.getItem('duckySignedUp') === 'true') {
    signupContainer.style.display = 'none';
    linkContainer.style.display   = 'block';
  }

  form.addEventListener('submit', async (evt) => {
    evt.preventDefault();
    const email = emailInput.value.trim();
    if (email) {
        // insert email into your Supabase table named "emails"
        const { data, error } = await supabaseClient
        .from('Users')
        .insert([{ email }]);

        if (error) {
        console.error(error);
        alert('Oops‚Äîsomething went wrong. Please try again.');
        } else {
        localStorage.setItem('duckySignedUp', 'true');
        signupContainer.style.display = 'none';
        linkContainer.style.display   = 'block';
        }
    }
  });
</script>
<!-- end gated block -->
<br>

----------------------

<br>
A few weeks ago I thought I was bothering my coworker by calling him to help debug something too often. In two separate conversations I exclaimed because I knew exactly what my bug was without him having said a word on the call‚Äîand felt embarrassed as he laughed at me through the computer screen.

I thought: _what if I could create an AI rubber ducky that I could call instead of him?_

<br>
**UX**

In my head I wanted to create a UX where I could talk to the rubber ducky and it would both hear me and see the code I was talking about, just like a Zoom call with your coworker.

<div class="video-container">
  <iframe
    width="560" height="315"
    src="https://www.youtube.com/embed/g_rt8n8Dnec?rel=0"
    frameborder="0"
    allowfullscreen>
  </iframe>
</div>

You can either click on a single line, or highlight multiple lines to send them as context to the model. 

<br>
**Quickstart**

1. BYO-API key

    <figure>
        <div style="text-align: center;">
            <img src="{{site.url}}/assets/ducky/set-api-key.png" alt="set API key"/>
        </div>
        <br>
    </figure>

2. Start Call

    <figure>
        <div style="text-align: center;">
            <img src="{{site.url}}/assets/ducky/start-call.gif" alt="start call"/>
        </div>
        <br>
    </figure>

3. Show Conversation History

    <figure>
        <div style="text-align: center;">
            <img src="{{site.url}}/assets/ducky/show-conversation-history.gif" alt="show conversation history"/>
        </div>
        <br>
    </figure>



<br>
**User Test**

To test if this is useful I created a dummy codebase for training a simple Vision Transformer for classification on a small subset of the [CIFAR-100](https://huggingface.co/datasets/uoft-cs/cifar100) dataset. I introduced a small bug in the `init()` of the model:

```diff
‚ùå num_patches = (img_size // patch_size) * (img_size // patch_size - 1)
‚úÖ num_patches = (img_size // patch_size) * (img_size // patch_size)
```

and asked my friend to use the AI rubber ducky to help him debug what was going wrong. 

<div class="video-container">
  <iframe
    width="560" height="315"
    src="https://www.youtube.com/embed/ITSSergQAos?rel=0"
    frameborder="0"
    allowfullscreen>
  </iframe>
</div>

<br>
**Why now?**

I'm seeing a divergence in the way people write code at Berkeley vs. at my job. Students / entrepreneurs are vibe coding to the max while my coworkers / friends at other companies are using LLM tools but still handwriting their bugfixes & features. I believe this is because production codebases are:
1. are about more than just the code i.e. there are business decisions being made outside the repo
2. are too large & expensive to feed into a prompt
3. will always need to be debugged, whether the code is human or AI generated

I can see a future where there are fewer programmers than there are today, but I believe the paradigm of asking an AI for help getting unstuck before bothering your coworker is here to stay for all knowledge work. 

<br>
**Cost**

This entire project cost around ~$40 to make, split evenly between a Cursor subscription and the OpenAI Realtime API. The spike in cost is while using the full 4o model while my friend did a 10 min user test. 4o-mini is around 4x [cheaper](https://openai.com/api/pricing/) for audio tokens and 10x cheaper for text tokens. 

<figure>
    <br>
    <div style="text-align: center;">
        <img src="{{site.url}}/assets/ducky/api-cost.png" alt="openai realtime api cost"/>
    </div>
    <br>
</figure>

<br>
**Future features:**
- Integrate with Cursor / GitHub Copilot
- Transcribe user's voice into chat
- Allow users to modify system prompt for personality
- Ducky learns from past conversations
- Track user file edits
- Let ducky have a cursor
- Visualize debugging attempt paths e.g.


<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, sans-serif;
            background-color: #f9fafb;
            padding: 20px;
        }

        .container {
            display: flex;
            flex-direction: column;
            margin: 0 auto;
            max-width: 768px;
            width: 100%;
            background-color: #f9fafb;
            padding: 16px;
            border-radius: 8px;
            gap: 40px;
        }

        .header {
            text-align: center;
        }

        .title {
            font-size: 24px;
            <!-- font-weight: bold; -->
            margin-bottom: 8px;
            color: #111827;
        }

        .subtitle {
            color: #6b7280;
            margin-top: -20px;
        }

        .timeline-container {
            position: relative;
        }

        .timeline-line {
            position: absolute;
            left: 84px;
            top: 0;
            bottom: 0;
            width: 4px;
            background-color: #60a5fa;
        }

        .timeline-events {
            display: flex;
            flex-direction: column;
            gap: 32px;
        }

        .timeline-event {
            display: flex;
            align-items: flex-start;
            position: relative;
        }

        .timestamp {
            width: 60px;
            padding-top: 8px;
            padding-right: 12px;
            text-align: right;
            font-weight: 600;
            color: #6b7280;
            flex-shrink: 0;
        }

        .content-box {
            flex-grow: 1;
            background-color: white;
            border-radius: 8px;
            padding: 16px;
            box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1);
            border-left: 4px solid;
        }

        .border-red { border-left-color: #ef4444; }
        .border-yellow { border-left-color: #eab308; }
        .border-blue { border-left-color: #3b82f6; }
        .border-purple { border-left-color: #a855f7; }
        .border-green { border-left-color: #22c55e; }

        .event-title {
            margin-bottom: 8px;
        }

        .title-red { color: #ef4444; }
        .title-yellow { color: #eab308; }
        .title-blue { color: #3b82f6; }
        .title-purple { color: #a855f7; }
        .title-green { color: #22c55e; }

        .event-description {
            color: #374151;
            line-height: 1.5;
        }

        .code-block {
            background-color: #f3f4f6;
            padding: 8px;
            margin-top: 8px;
            border-radius: 4px;
            font-family: 'Courier New', Consolas, Monaco, monospace;
            font-size: 14px;
            color: #1f2937;
        }

        .success-message {
            margin-top: 8px;
            font-weight: 600;
            color: #059669;
        }

        @media (max-width: 768px) {
            .container {
                width: 95%;
            }
            
            .timestamp {
                width: 50px;
                font-size: 14px;
                padding-right: 8px;
            }
            
            .timeline-line {
                left: 66px;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h4 style="margin-bottom: -10px">Vision Transformer Debugging Journey</h4>
        </div>
        <!-- Timeline visualization -->
        <div class="timeline-container">
            <!-- Main timeline line -->
            <div class="timeline-line"></div>
            <!-- Timeline events -->
            <div class="timeline-events">
                <!-- Initial problem -->
                <div class="timeline-event">
                    <div class="timestamp">0:00</div>
                    <div class="content-box border-red">
                        <h4 class="event-title">Problem Identified</h4>
                        <p class="event-description">User is experiencing an error with a Vision Transformer (ViT) model implementation</p>
                    </div>
                </div>
                <!-- Code exploration -->
                <div class="timeline-event">
                    <div class="timestamp">0:30</div>
                    <div class="content-box border-yellow">
                        <h4 class="event-title">Initial Exploration</h4>
                        <p class="event-description">Started exploring model.py, looking at model initialization parameters and forward pass implementation</p>
                        <div class="code-block">model = ViT(
                            img_size=IMG_SIZE,
                            patch_size=16,
                            emb_dim=64,
                            depth=4,
                            num_heads=2
                            )
                        </div>
                    </div>
                </div>
                <!-- First insight -->
                <div class="timeline-event">
                    <div class="timestamp">2:00</div>
                    <div class="content-box border-blue">
                        <h4 class="event-title">First Insight</h4>
                        <p class="event-description">Discovered potential issue with patch calculation:</p>
                        <div class="code-block">num_patches = (img_size // patch_size) * (img_size // patch_size - 1) # Wrong calculation</div>
                    </div>
                </div>
                <!-- Key discovery -->
                <div class="timeline-event">
                    <div class="timestamp">5:00</div>
                    <div class="content-box border-purple">
                        <h4 class="event-title">Key Discovery</h4>
                        <p class="event-description">Identified critical error in forward pass:</p>
                        <div class="code-block">cls_tokens = self.cls_token.expand(b, -1, -1)</div>
                        <p class="event-description" style="margin-top: 8px;">Variable 'cls_tokens' is referenced but 'self.cls_token' is undefined in the model!</p>
                    </div>
                </div>
                <!-- Solution -->
                <div class="timeline-event">
                    <div class="timestamp">7:30</div>
                    <div class="content-box border-green">
                        <h4 class="event-title">Solution</h4>
                        <p class="event-description">Added missing class token initialization in __init__:</p>
                        <div class="code-block">self.cls_token = nn.Parameter(torch.randn(1, 1, emb_dim))</div>
                        <p class="success-message">‚úì Bug fixed! Model now works properly</p>
                    </div>
                </div>
            </div>
        </div>
    </div>
</body>
</html>


#### References:

- [Azure / OpenAI Realtime API docs](https://learn.microsoft.com/en-us/azure/ai-services/openai/realtime-audio-reference)
- [OpenAI Realtime API docs](https://platform.openai.com/docs/guides/realtime)
- [OpenAI Realtime API Example Repo](https://github.com/openai/openai-realtime-console)
- [OpenAI API Pricing](https://openai.com/api/pricing/)
- [Publishing VSCode Extensions](https://code.visualstudio.com/api/working-with-extensions/publishing-extension)
