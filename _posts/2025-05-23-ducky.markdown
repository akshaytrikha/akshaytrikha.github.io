---
layout: post
title: "AI Rubber Ducky Pair Programmer"
date: 2025-05-23 16:06:17 +0000
categories: deep-learning
---

Please try out the extension on the VSCode extension marketplace and let me know what you think! Enter your email to get access:


<!-- gated signup + link reveal -->
<div id="signup-container">
  <form id="signup-form">
    <input
      type="email"
      id="email-input"
      name="email"
      placeholder="you@domain.com"
      required
    />
    <button type="submit">Sign up ‚Üí</button>
  </form>
</div>

<div id="link-container" style="display:none; margin-top:1em;">
  <a
    href="https://marketplace.visualstudio.com/items?itemName=duckydev.duckydev"
    target="_blank"
    rel="noopener"
  >
    üê§ Get the Ducky VSCode extension
  </a>
</div>

<script src="https://cdn.jsdelivr.net/npm/@supabase/supabase-js"></script>
<script>
  // initialize Supabase client
  const supabaseClient = supabase.createClient(
    'https://jpwoombwzqxfxebrpzkl.supabase.co',
    'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6Impwd29vbWJ3enF4ZnhlYnJwemtsIiwicm9sZSI6ImFub24iLCJpYXQiOjE3NDgyMTY4NDgsImV4cCI6MjA2Mzc5Mjg0OH0.UzRsuRw63TN6rFNtLtBpXZy8JKvrzH1tliS7D_SgI50'
  );

  const form            = document.getElementById('signup-form');
  const emailInput      = document.getElementById('email-input');
  const signupContainer = document.getElementById('signup-container');
  const linkContainer   = document.getElementById('link-container');

  // if user already signed up, show the link immediately
  if (localStorage.getItem('duckySignedUp') === 'true') {
    signupContainer.style.display = 'none';
    linkContainer.style.display   = 'block';
  }

  form.addEventListener('submit', async (evt) => {
    evt.preventDefault();
    const email = emailInput.value.trim();
    if (email) {
        // insert email into your Supabase table named "emails"
        const { data, error } = await supabaseClient
        .from('Users')
        .insert([{ email }]);

        if (error) {
        console.error(error);
        alert('Oops‚Äîsomething went wrong. Please try again.');
        } else {
        localStorage.setItem('duckySignedUp', 'true');
        signupContainer.style.display = 'none';
        linkContainer.style.display   = 'block';
        }
    }
  });
</script>
<!-- end gated block -->
<br>

----------------------

<br>
A few weeks ago I thought I was bothering my coworker by calling him to help debug something too often. In two separate conversations I exclaimed because I knew exactly what my bug was without him having said a word on the call‚Äîand felt embarrassed as he laughed at me through the computer screen.

I thought: _what if I could create an AI rubber ducky that I could call instead of him?_

<br>
**UX**

In my head I wanted to create a UX where I could talk to the rubber ducky and it would both hear me and see the code I was talking about, just like a Zoom call with your coworker.

<div class="video-container">
  <iframe
    width="560" height="315"
    src="https://www.youtube.com/embed/g_rt8n8Dnec?rel=0"
    frameborder="0"
    allowfullscreen>
  </iframe>
</div>

You can either click on a single line, or highlight multiple lines to send them as context to the model. 

<br>
**Quickstart**

1. BYO-API key

    <figure>
        <div style="text-align: center;">
            <img src="{{site.url}}/assets/ducky/set-api-key.png" alt="set API key"/>
        </div>
        <br>
    </figure>

2. Start Call

    <figure>
        <div style="text-align: center;">
            <img src="{{site.url}}/assets/ducky/start-call.gif" alt="start call"/>
        </div>
        <br>
    </figure>

3. Show Conversation History

    <figure>
        <div style="text-align: center;">
            <img src="{{site.url}}/assets/ducky/show-conversation-history.gif" alt="show conversation history"/>
        </div>
        <br>
    </figure>



<br>
**User Test**

To test if this is useful I created a dummy codebase for training a simple Vision Transformer for classification on a small subset of the [CIFAR-100](https://huggingface.co/datasets/uoft-cs/cifar100) dataset. I introduced a small bug in the `init()` of the model:

```diff
‚ùå num_patches = (img_size // patch_size) * (img_size // patch_size - 1)
‚úÖ num_patches = (img_size // patch_size) * (img_size // patch_size)
```

and asked my friend to use the AI rubber ducky to help him debug what was going wrong. 

<div class="video-container">
  <iframe
    width="560" height="315"
    src="https://www.youtube.com/embed/ITSSergQAos?rel=0"
    frameborder="0"
    allowfullscreen>
  </iframe>
</div>

<br>
**Why now?**

I'm seeing a divergence in the way people write code at Berkeley vs. at my job. Students / entrepreneurs are vibe coding to the max while my coworkers / friends at other companies are using LLM tools but still handwriting their bugfixes & features. I believe this is because production codebases are:
1. are about more than just the code i.e. there are business decisions being made outside the repo
2. are too large & expensive to feed into a prompt
3. will always need to be debugged, whether the code is human or AI generated

I can see a future where there are fewer programmers than there are today, but I believe the paradigm of asking an AI for help getting unstuck before bothering your coworker is here to stay for all knowledge work. 

<br>
**Cost**

This entire project cost around ~$40 to make, split evenly between a Cursor subscription and the OpenAI Realtime API. The spike in cost is while using the full 4o model while my friend did a 10 min user test. 4o-mini is around 4x [cheaper](https://openai.com/api/pricing/) for audio tokens and 10x cheaper for text tokens. 

<figure>
    <br>
    <div style="text-align: center;">
        <img src="{{site.url}}/assets/ducky/api-cost.png" alt="openai realtime api cost"/>
    </div>
    <br>
</figure>

<br>
**Future features:**
- Visualize debugging attempt paths
- Integrate with Cursor / GitHub Copilot
- Transcribe user's voice into chat
- Allow users to modify system prompt for personality
- Ducky learns from past conversations
- Track user file edits
- Let ducky have a cursor

#### References:

- [Azure / OpenAI Realtime API docs](https://learn.microsoft.com/en-us/azure/ai-services/openai/realtime-audio-reference)
- [OpenAI Realtime API docs](https://platform.openai.com/docs/guides/realtime)
- [OpenAI Realtime API Example Repo](https://github.com/openai/openai-realtime-console)
- [OpenAI API Pricing](https://openai.com/api/pricing/)
- [Publishing VSCode Extensions](https://code.visualstudio.com/api/working-with-extensions/publishing-extension)
